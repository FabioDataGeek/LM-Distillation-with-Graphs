{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/usrvol/processed_tensors/SNLI/dev/sintactic/bert-base-uncased/raw/sintactic0.pkl', 'rb') as f:\n",
    "    tensors = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Two',\n",
       "  'women',\n",
       "  'are',\n",
       "  'embracing',\n",
       "  'while',\n",
       "  'holding',\n",
       "  'to',\n",
       "  'go',\n",
       "  'packages',\n",
       "  '.']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[0][0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 3, 3, 3, 5, 5, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 5, 9, 4, 8, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[0][0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/usrvol/processed_data/SNLI/dev/sintactic/sintactic0.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeDataView({1: {'label': 'Two'}, 2: {'label': 'women'}, 3: {'label': 'are'}, 4: {'label': 'embracing'}, 5: {'label': 'while'}, 6: {'label': 'holding'}, 7: {'label': 'to'}, 8: {'label': 'go'}, 9: {'label': 'packages'}, 10: {'label': '.'}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeDataView([(2, 1, {'label': 'num'}), (4, 2, {'label': 'nsubj'}), (4, 3, {'label': 'aux'}), (4, 6, {'label': 'advcl'}), (4, 10, {'label': 'punct'}), (6, 5, {'label': 'mark'}), (6, 9, {'label': 'dobj'}), (8, 7, {'label': 'dep'}), (9, 8, {'label': 'amod'})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/usrvol/utils/bert-base-uncased_specific_tensors.pkl', 'rb') as f:\n",
    "    tensors = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeDataView([(2, 1, {'label': 'num'}), (4, 2, {'label': 'nsubj'}), (4, 3, {'label': 'aux'}), (4, 6, {'label': 'advcl'}), (4, 10, {'label': 'punct'}), (6, 5, {'label': 'mark'}), (6, 9, {'label': 'dobj'}), (8, 7, {'label': 'dep'}), (9, 8, {'label': 'amod'})])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeDataView({1: {'label': 'Two'}, 2: {'label': 'women'}, 3: {'label': 'are'}, 4: {'label': 'embracing'}, 5: {'label': 'while'}, 6: {'label': 'holding'}, 7: {'label': 'to'}, 8: {'label': 'go'}, 9: {'label': 'packages'}, 10: {'label': '.'}})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num', 'nsubj', 'aux', 'advcl', 'punct', 'mark', 'dobj', 'dep', 'amod']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[0][0].edge_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 19])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[0][0].edge_index.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two',\n",
       " 'women',\n",
       " 'are',\n",
       " 'embracing',\n",
       " 'while',\n",
       " 'holding',\n",
       " 'to',\n",
       " 'go',\n",
       " 'packages',\n",
       " '.']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[0][0].label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= tensors[0][0].edge_index[0][0:len(tensors[0][0].edge_label[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= tensors[0][0].edge_index[1][0:len(tensors[0][0].edge_label[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26353/3442007704.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  stacked = torch.stack([torch.tensor(a), torch.tensor(b)], dim=0)\n"
     ]
    }
   ],
   "source": [
    "stacked = torch.stack([torch.tensor(a), torch.tensor(b)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = []\n",
    "entities = []\n",
    "for i in range(len(stacked[0])):\n",
    "    first, second = stacked[0][i].item(), stacked[1][i].item()\n",
    "    first_string, second_string, relation = tensors[0][0].label[0][first], tensors[0][0].label[0][second], tensors[0][0].edge_label[0][i]\n",
    "    if not first_string in entities:\n",
    "        entities.append(first_string)\n",
    "    if not second_string in entities:\n",
    "        entities.append(second_string)\n",
    "    triples.append((first_string, relation, second_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['women',\n",
       " 'Two',\n",
       " 'embracing',\n",
       " 'are',\n",
       " 'holding',\n",
       " '.',\n",
       " 'while',\n",
       " 'packages',\n",
       " 'go',\n",
       " 'to']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate the metadata that will receive HANConv and HGTConv initially, indicating the name of the different nodes and relations in all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triples(pytorch_data, entities, triples):\n",
    "    a = pytorch_data.edge_index[0][0:len(pytorch_data.edge_label[0])]\n",
    "    b = pytorch_data.edge_index[1][0:len(pytorch_data.edge_label[0])]\n",
    "    stacked = torch.stack([torch.tensor(a), torch.tensor(b)], dim=0)\n",
    "    for i in range(len(stacked[0])):\n",
    "                first, second = stacked[0][i].item(), stacked[1][i].item()\n",
    "                first_string, second_string, relation = first.label[0][first], first.label[0][second], first.edge_label[0][i]\n",
    "                if not first_string in entities:\n",
    "                    entities.append(first_string)\n",
    "                if not second_string in entities:\n",
    "                    entities.append(second_string)\n",
    "                triples.append((first_string, relation, second_string))\n",
    "\n",
    "    return list(set(entities)), list(set(triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = []\n",
    "triples = []\n",
    "for dataset in ['train', 'dev,', 'test']:\n",
    "    folder = os.listdir(f\"/usrvol/processed_tensors/SNLI/{dataset}/sintactic/bert-base-uncased/raw/\")\n",
    "    for file in folder:\n",
    "        with open(f\"/usrvol/processed_tensors/SNLI/{dataset}/sintactic/bert-base-uncased/raw/{file}\", 'rb') as f:\n",
    "            tensors = pkl.load(f)\n",
    "        for tensor in tensors:\n",
    "            first = tensor[0]\n",
    "            entities, triples = get_triples(first, entities, triples)\n",
    "            second = tensor[1]\n",
    "            entities, triples = get_triples(second, entities, triples)\n",
    "\n",
    "metadata = [entities, triples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for dimension 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msize()\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for dimension 0 with size 10"
     ]
    }
   ],
   "source": [
    "tensors[0][0].x[10].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader HGTConv, HANConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triples(pytorch_data, entities, triples):\n",
    "    a = pytorch_data.edge_index[0][0:len(pytorch_data.edge_label[0])]\n",
    "    b = pytorch_data.edge_index[1][0:len(pytorch_data.edge_label[0])]\n",
    "    stacked = torch.stack([torch.tensor(a), torch.tensor(b)], dim=0)\n",
    "    for i in range(len(stacked[0])):\n",
    "                first, second = stacked[0][i].item(), stacked[1][i].item()\n",
    "                first_string, second_string, relation = first.label[0][first], first.label[0][second], first.edge_label[0][i]\n",
    "                if not first_string in entities:\n",
    "                    entities.append(first_string)\n",
    "                if not second_string in entities:\n",
    "                    entities.append(second_string)\n",
    "                triples.append((first_string, relation, second_string))\n",
    "\n",
    "    return list(set(entities)), list(set(triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicts(pytorch_data, edge_tensors):\n",
    "    x_dict = {}\n",
    "    triples_dict = {}\n",
    "    a = pytorch_data.edge_index[0][0:len(pytorch_data.edge_label[0])]\n",
    "    b = pytorch_data.edge_index[1][0:len(pytorch_data.edge_label[0])]\n",
    "    stacked = torch.stack([torch.tensor(a), torch.tensor(b)], dim=0)\n",
    "    for i in range(len(stacked[0])):\n",
    "                first, second = stacked[0][i].item(), stacked[1][i].item()\n",
    "                first_string, second_string, relation = first.label[0][first], first.label[0][second], first.edge_label[0][i]\n",
    "                if not first_string in entities:\n",
    "                    entities.append(first_string)\n",
    "                if not second_string in entities:\n",
    "                    entities.append(second_string)\n",
    "                specific_tensor = edge_tensors[relation]\n",
    "                if not first_string in x_dict:\n",
    "                    position = pytorch_data.edge_index[0][i]\n",
    "                    x_dict[first_string] = pytorch_data.x[position]\n",
    "                \n",
    "                if not second_string in x_dict:\n",
    "                    position = pytorch_data.edge_index[1][i]\n",
    "                    x_dict[second_string] = pytorch_data.x[position]\n",
    "                triples_dict[first_string, relation, second_string] = specific_tensor\n",
    "    \n",
    "    return x_dict, triples_dict\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader HEATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/usrvol/processed_tensors/SNLI/dev/sintactic+semantic+constituency/bert-base-uncased/raw/sintactic_semantic_constituency0.pkl', 'rb') as f:\n",
    "    tensors = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two',\n",
       " 'women',\n",
       " 'are',\n",
       " 'women',\n",
       " 'while',\n",
       " 'holding',\n",
       " 'to',\n",
       " 'go',\n",
       " 'packages',\n",
       " 'are',\n",
       " '«SENTENCE»',\n",
       " '«NOUN PHRASE»',\n",
       " 'Two',\n",
       " '«VERB PHRASE»',\n",
       " '«VERB PHRASE»',\n",
       " 'embracing',\n",
       " '«SUBORDINATE CLAUSE»',\n",
       " 'while',\n",
       " '«SENTENCE»',\n",
       " '«VERB PHRASE»',\n",
       " 'holding',\n",
       " '«NOUN PHRASE»',\n",
       " '«ADJECTIVE PHRASE»',\n",
       " 'to',\n",
       " 'go',\n",
       " 'packages',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[0][0].label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type = []\n",
    "for i in range(len(tensors[0][0].label[0])):\n",
    "    if tensors[0][0].label[0][i].startswith('«') and tensors[0][0].label[0][i].endswith('»'):\n",
    "        node_type.append(0)\n",
    "    else:\n",
    "        node_type.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2596/17800947.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  node_type = torch.tensor(node_type, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "node_type = torch.tensor(node_type, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dicts import *\n",
    "\n",
    "sintactics = list(SINTACTIC_DICT.keys())\n",
    "semantics = list(SEMANTIC_DICT.keys())\n",
    "\n",
    "edge_types = []\n",
    "for i in range(len(tensors[0][0].edge_label[0])):\n",
    "    if tensors[0][0].edge_label[0][i] == 'constituency relation':\n",
    "        edge_types.append(2)\n",
    "    elif tensors[0][0].edge_label[0][i] in sintactics:\n",
    "        edge_types.append(0)\n",
    "    elif tensors[0][0].edge_label[0][i] in semantics:\n",
    "        edge_types.append(1)\n",
    "    else:\n",
    "        raise ValueError('Edge type not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = torch.tensor(edge_types, dtype=torch.long)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
