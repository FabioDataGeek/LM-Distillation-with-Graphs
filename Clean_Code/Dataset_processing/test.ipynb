{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/usrvol/data/RTE1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_RTE(folder):\n",
    "    data_list = []\n",
    "    filename_list = []\n",
    "    files = os.listdir(folder)\n",
    "    for file in files:\n",
    "        if file.endswith(\"xml\"):\n",
    "            data = []\n",
    "            filename = file.split('.')[0]\n",
    "            with open(f\"{folder}/{file}\", \"r\") as f:\n",
    "                tree = ET.parse(f)\n",
    "            root = tree.getroot()\n",
    "            data = []\n",
    "            for child in root:\n",
    "                for child2 in child:\n",
    "                    for element in child2.iter('t'):\n",
    "                        sentence1 = element.text\n",
    "                    for element in child2.iter('h'):\n",
    "                        sentence2 = element.text\n",
    "                info = {'sentence1': sentence1, 'sentence2': sentence2, \n",
    "                        'label': child.attrib['value'], 'id': child.attrib['id'],\n",
    "                        'task': child.attrib['task']}\n",
    "                data.append(info)\n",
    "            data_list.append(data)\n",
    "            filename_list.append(filename)\n",
    "    return data_list, filename_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list, filename_list = process_RTE(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dev2'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/usrvol/data/SciTail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scitail_1.0_dev.txt', 'scitail_1.0_train.txt', 'scitail_1.0_test.txt']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSciTail(folder):\n",
    "    files = os.listdir(folder)\n",
    "    data_list = []\n",
    "    filename_list = []\n",
    "    for file in files:\n",
    "        if file.endswith(\"txt\"):\n",
    "            data = []\n",
    "            filename = file.split('_')[2].split('.')[0]\n",
    "            with open(f\"{folder}/{file}\", 'r') as f:\n",
    "                for line in f:\n",
    "                    data.append(json.loads(line))\n",
    "            data_list.append(data)\n",
    "            filename_list.append(filename)\n",
    "    return data_list, filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list, filename_list = processSciTail(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1_binary_parse': '( ( This expansion ) ( ( ( ( causes ( the light ) ) ( from ( distant stars ) ) ) ( to ( be ( shifted ( towards ( ( the ( red end ) ) ( of ( the spectrum ) ) ) ) ) ) ) ) . ) )',\n",
       " 'sentence1_parse': '(ROOT (S (NP (DT This) (NN expansion)) (VP (VBZ causes) (NP (DT the) (NN light)) (PP (IN from) (NP (JJ distant) (NNS stars))) (S (VP (TO to) (VP (VB be) (VP (VBN shifted) (PP (IN towards) (NP (NP (DT the) (JJ red) (NN end)) (PP (IN of) (NP (DT the) (NN spectrum)))))))))) (. .)))',\n",
       " 'gold_label': 'entailment',\n",
       " 'sentence2_binary_parse': '( Red-shift ( ( ( refers ( to ( ( a shift ) ( toward red ) ) ) ) ( in ( ( the spectrum ) ( from stars ) ) ) ) . ) )',\n",
       " 'sentence1': 'This expansion causes the light from distant stars to be shifted towards the red end of the spectrum.',\n",
       " 'annotator_labels': ['entailment',\n",
       "  'entailment',\n",
       "  'entailment',\n",
       "  'entailment',\n",
       "  '-'],\n",
       " 'sentence2_parse': '(ROOT (S (NP (NNP Red-shift)) (VP (VBZ refers) (PP (TO to) (NP (NP (DT a) (NN shift)) (PP (IN toward) (NP (NN red))))) (PP (IN in) (NP (NP (DT the) (NN spectrum)) (PP (IN from) (NP (NNS stars)))))) (. .)))',\n",
       " 'sentence2': 'Red-shift refers to a shift toward red in the spectrum from stars.'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/usrvol/processed_data/RTE1/dev/sintactic0.pkl\", \"rb\") as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For paper images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supar import Parser\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sintactic tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "torch.cuda.set_device(device)\n",
    "model = 'dep-biaffine-roberta-en'\n",
    "sint = Parser.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I saw Sarah with a telescope.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = sint.predict(sentence, verbose=False, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\tI\t_\t_\t_\t_\t2\tnsubj\t_\t_\n",
       "2\tsaw\t_\t_\t_\t_\t0\troot\t_\t_\n",
       "3\tSarah\t_\t_\t_\t_\t2\tdobj\t_\t_\n",
       "4\twith\t_\t_\t_\t_\t2\tprep\t_\t_\n",
       "5\ta\t_\t_\t_\t_\t6\tdet\t_\t_\n",
       "6\ttelescope\t_\t_\t_\t_\t4\tpobj\t_\t_\n",
       "7\t.\t_\t_\t_\t_\t2\tpunct\t_\t_"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "semantic tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "torch.cuda.set_device(device)\n",
    "model='sdp-vi-en'\n",
    "sem = Parser.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I saw Sarah with a telescope.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = sem.predict(sentence, verbose=False, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\tI\t_\t_\t_\t_\t_\t_\t2:ARG1\t_\n",
       "2\tsaw\t_\t_\t_\t_\t_\t_\t0:root|2:ARG1\t_\n",
       "3\tSarah\t_\t_\t_\t_\t_\t_\t2:ARG2\t_\n",
       "4\twith\t_\t_\t_\t_\t_\t_\t_\t_\n",
       "5\ta\t_\t_\t_\t_\t_\t_\t_\t_\n",
       "6\ttelescope\t_\t_\t_\t_\t_\t_\t4:ARG2|5:BV\t_\n",
       "7\t.\t_\t_\t_\t_\t_\t_\t_\t_"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constituency tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "torch.cuda.set_device(device)\n",
    "model='con-crf-roberta-en'\n",
    "con = Parser.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I saw Sarah with a telescope.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = con.predict(sentence, verbose=False, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TOP (S (NP (_ I)) (VP (_ saw) (NP (_ Sarah)) (PP (_ with) (NP (_ a) (_ telescope)))) (_ .)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
