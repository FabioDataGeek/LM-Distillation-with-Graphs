{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supar import Parser\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser.load('dep-biaffine-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = parser.predict('I saw Sarah with a telescope.', lang='en', prob=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(n_sentences=1, n_batches=1, n_buckets=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\tI\t_\t_\t_\t_\t2\tnsubj\t_\t_\n",
       "2\tsaw\t_\t_\t_\t_\t0\troot\t_\t_\n",
       "3\tSarah\t_\t_\t_\t_\t2\tdobj\t_\t_\n",
       "4\twith\t_\t_\t_\t_\t2\tprep\t_\t_\n",
       "5\ta\t_\t_\t_\t_\t6\tdet\t_\t_\n",
       "6\ttelescope\t_\t_\t_\t_\t4\tpobj\t_\t_\n",
       "7\t.\t_\t_\t_\t_\t2\tpunct\t_\t_"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árbol de dependencias sintáctico con mayor F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\tI\t_\t_\t_\t_\t2\tnsubj\t_\t_\n",
       "2\tsaw\t_\t_\t_\t_\t0\troot\t_\t_\n",
       "3\tSarah\t_\t_\t_\t_\t2\tdobj\t_\t_\n",
       "4\twith\t_\t_\t_\t_\t2\tprep\t_\t_\n",
       "5\ta\t_\t_\t_\t_\t6\tdet\t_\t_\n",
       "6\ttelescope\t_\t_\t_\t_\t4\tpobj\t_\t_\n",
       "7\t.\t_\t_\t_\t_\t2\tpunct\t_\t_"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin = Parser.load('dep-biaffine-roberta-en')\n",
    "sin.predict(['I', 'saw', 'Sarah', 'with', 'a', 'telescope', '.'], verbose=False)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your example, the sentence is “I saw Sarah with a telescope.”. The word “saw” is the root of the sentence. The word “I” is a nominal subject (nsubj) of “saw”, “Sarah” is a direct object (dobj) of “saw”, “with” is a preposition (prep) connected to “saw”, “a” is a determiner (det) of “telescope”, and “telescope” is the object of the preposition (pobj) “with”. The period is punctuation (punct) connected to “saw”. The HEAD column indicates the ID of the parent of each word. For example, “I” (ID 1) is a child of “saw” (ID 2), so its HEAD is 2.\n",
    "\n",
    "Column 7 represents the position of the parent of the current node, if 0 means it is the root of the tree.\n",
    "\n",
    "Each element in the sentence is classified according to Universal Stanford dependency relation to the HEAD:\n",
    "\n",
    "    nsubj: Nominal subject\n",
    "    obj: Object\n",
    "    iobj: Indirect object\n",
    "    csubj: Clausal subject\n",
    "    ccomp: Clausal complement\n",
    "    xcomp: Open clausal complement\n",
    "    nmod: Nominal modifier\n",
    "    advmod: Adverbial modifier\n",
    "    amod: Adjectival modifier\n",
    "    conj: Conjunct\n",
    "    cc: Coordinating conjunction\n",
    "    aux: Auxiliary\n",
    "    cop: Copula\n",
    "    det: Determiner\n",
    "    clf: Classifier\n",
    "    case: Case marking\n",
    "    mark: Marker\n",
    "    punct: Punctuation\n",
    "    dep: Unspecified dependency\n",
    "    root: initial node in the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árbol de dependencias semántico con mayor F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "sem = Parser.load('sdp-vi-roberta-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\tI\t_\t_\t_\t_\t_\t_\t_\t_\n",
       "2\tsaw\t_\t_\t_\t_\t_\t_\t_\t_\n",
       "3\tSarah\t_\t_\t_\t_\t_\t_\t_\t_\n",
       "4\twith\t_\t_\t_\t_\t_\t_\t_\t_\n",
       "5\ta\t_\t_\t_\t_\t_\t_\t_\t_\n",
       "6\ttelescope\t_\t_\t_\t_\t_\t_\t_\t_\n",
       "7\t.\t_\t_\t_\t_\t_\t_\t_\t_"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem.predict(['I', 'saw', 'Sarah', 'with', 'a', 'telescope', '.'], verbose=False)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece ser que el modelo que utiliza roberta no funciona, nos salta un mensaje de que sería conveniente entrenarlo nosotros mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = Parser.load('sdp-biaffine-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-04 09:26:15 INFO] Loading the data\n",
      "[2024-03-04 09:26:16 INFO] \n",
      "Dataset(n_sentences=1, n_batches=1, n_buckets=1)\n",
      "[2024-03-04 09:26:16 INFO] Making predictions on the data\n",
      "[2024-03-04 09:26:16 INFO] 0:00:00.011046s elapsed, 724.24 Tokens/s, 90.53 Sents/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1\tI\t_\t_\t_\t_\t_\t_\t2:ARG1\t_\n",
       "2\tsaw\t_\t_\t_\t_\t_\t_\t0:root\t_\n",
       "3\tSarah\t_\t_\t_\t_\t_\t_\t2:ARG2\t_\n",
       "4\twith\t_\t_\t_\t_\t_\t_\t_\t_\n",
       "5\ta\t_\t_\t_\t_\t_\t_\t_\t_\n",
       "6\ttelescope\t_\t_\t_\t_\t_\t_\t4:ARG2|5:BV\t_\n",
       "7\t.\t_\t_\t_\t_\t_\t_\t_\t_"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem.predict(['I', 'saw', 'Sarah', 'with', 'a', 'telescope','.'], verbose=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/yzhangcs/parser/releases/download/v1.1.0/dm.vi.sdp.lstm.tag-char-lemma.zip to /root/.cache/supar/dm.vi.sdp.lstm.tag-char-lemma.zip\n",
      "100%|██████████| 497M/497M [00:44<00:00, 11.7MB/s] \n"
     ]
    }
   ],
   "source": [
    "sem = Parser.load('sdp-vi-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\tI\t_\t_\t_\t_\t_\t_\t2:ARG1\t_\n",
       "2\tsaw\t_\t_\t_\t_\t_\t_\t0:root|2:ARG1\t_\n",
       "3\tSarah\t_\t_\t_\t_\t_\t_\t2:ARG2\t_\n",
       "4\twith\t_\t_\t_\t_\t_\t_\t_\t_\n",
       "5\ta\t_\t_\t_\t_\t_\t_\t_\t_\n",
       "6\ttelescope\t_\t_\t_\t_\t_\t_\t4:ARG2|5:BV\t_\n",
       "7\t.\t_\t_\t_\t_\t_\t_\t_\t_"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem.predict(['I', 'saw', 'Sarah', 'with', 'a', 'telescope','.'], verbose=False)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Roles: These are the roles that a predicate and its associated arguments can take on in a sentence. The format is HEAD:ROLE, where HEAD is the ID of the head word and ROLE is the semantic role. For example, 0:root indicates that the current word is the root of the sentence, 4:ARG1 indicates that the current word is the first argument (ARG1) of the word with ID 4, and so on.\n",
    "\n",
    "In your example, the sentence is “I saw Sarah with a telescope.”. The word “saw” is the root of the sentence. The word “I” is the first argument (ARG1) of “saw”, “Sarah” is the second argument (ARG2) of “saw”, and “telescope” is the second argument (ARG2) of “with” and bears a variable (BV) related to “a”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De entre los tres modelos de sdp que tenemos disponibles, RoBERTa no funciona bien, y los otros dos dan resultados muy similares, aunque tenemos alguna desconexión importante en el arbol, ya que \"telescope\" no está ligado a ningún sujeto o verbo, lo cual puede considerarse un error. No obstante, si se combina el árbol semántico con el sintáctico, este error no será tan notorio, ya que la relación queda implícita a nivel sintáctico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árbol de constituencia con mayor F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "con = Parser.load('con-crf-roberta-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TOP                       \n",
      "               |                         \n",
      "               S                        \n",
      "  _____________|______________________   \n",
      " |             VP                     | \n",
      " |    _________|____                  |  \n",
      " |   |    |         PP                | \n",
      " |   |    |     ____|___              |  \n",
      " NP  |    NP   |        NP            | \n",
      " |   |    |    |     ___|______       |  \n",
      " _   _    _    _    _          _      _ \n",
      " |   |    |    |    |          |      |  \n",
      " I  saw Sarah with  a      telescope  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "con.predict(['I', 'saw', 'Sarah', 'with', 'a', 'telescope', '.'], verbose=False)[0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TOP (S (NP (_ I)) (VP (_ saw) (NP (_ Sarah)) (PP (_ with) (NP (_ a) (_ telescope)))) (_ .)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.predict(['I', 'saw', 'Sarah', 'with', 'a', 'telescope', '.'], verbose=False)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El árbol de constituencia parece ser que se representa bastante bien con RoBERTa, con la información del árbol representada en el segundo formato podemos formar un grafo de constituencia. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
